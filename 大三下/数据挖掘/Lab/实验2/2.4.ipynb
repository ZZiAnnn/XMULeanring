{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>2.4 Pandas数据预处理</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.1数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.检测与处理重复值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个去重函数，利用列表去重，该方法去重效果好，但是代码较长，不够简练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)\t记录重复\n",
    "针对数据的特征某几个记录的值完全相同，记录重复主要有三种方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①自定义一个去重函数，利用列表去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delRep(list1):\n",
    "    list2=[]\n",
    "    for i in list1:\n",
    "        if i not in list2: \n",
    "            list2.append(i)\n",
    "    return list2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series(data=[1,2,3,2,4,5,1])\n",
    "s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delRep(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "②利用集合（set）的元素是唯一的特性去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③Pandas自带drop_duplicates函数。该方法只对DataFrame或者Series类型有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)\t特征重复\n",
    "利用特征间的相似度将两个相似度为1（即完全相同）的特征去除一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是用这种方法进行去重存在一个问题，即该方法只能对数值型重复进行去重，类别型的相似度无法通过相似系数来进行衡量。除了可以使用相似度矩阵实现特征去重以外，也可以考虑选择DataFrame.equals函数进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.检测与处理缺失值\n",
    "缺失值的定义：数据中的由于缺少信息而造成某个或某些特征的值不完整，那么这些值即可称为缺失值。<br>\n",
    "Pandas提供了识别缺失值（NaN）的两种方法：isnull函数和notnull函数，这两个函数运行后返回的都是布尔值，即所有数据的True或False矩阵。<br>\n",
    "为了便于统计，在使用isnull或者notnull的同时，结合使用sum函数，可以检测数据中缺失值的分布以及统计数据中包含缺失值的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理缺失值常使用三种方法：删除法、替换法、插值法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)\t删除法\n",
    "分为删除观测记录（行）和删除特征（列）两种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.randn(5, 3), index = list('12345'), columns = ['A', 'B', 'C'])        # 随机产生5行3列的数据    \n",
    "df.iloc[1, 1:-1] = np.nan        # 将第二行的第二个到倒数第二个数据定义为缺失，0是索引第一行\n",
    "df.iloc[1:-1, 2] = np.nan       # 将第三列的第二个到倒数第二个数据定义为缺失，0是索引第一列\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0)   #删除所有带缺失数据的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)   #删除所有带缺失数据的列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)\t替换法\n",
    "具体操作是指定一个特定的值对缺失值的替换。<br>\n",
    "<br>\n",
    "当缺失值所在的数据集类型为数值型时，常以数据集的平均数（mean）或中位数（median）等统计数据对缺失值进行替换。<br>如果缺失值所在的数据集类型为类别型，那么常常使用众数来进行缺失值的替换。<br>\n",
    "<br>\n",
    "Pandas中也提供了替换缺失值为具体数值的函数fillna，用于对缺失数据的填充<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean()) #用列平均数填充该缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='bfill') #用下一个非缺失值填充该缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill') #用上一个非缺失值填充该缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3)\t插值法\n",
    "插值法也是常用的处理缺失值的方法之一，是一种通过已知的、离散的数据点，在范围内推求新数据点的方法。常用的插值法有线性插值、多项式插值和样条插值等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性插值：一种较为简单的插值方法，它是根据已知的值推导出线性方程，然后通过线性方程的求解得到缺失值。<br>\n",
    "多项式插值：根据已知的值进行多项式的拟合，使得现有的数据支持这个多项式，然后根据多项式来求解缺失值，常见的多项式插值法有拉格朗日插值和牛顿插值等。<br>\n",
    "样条插值：是一种基于数学函数的插值方法，对每相邻两个数据点进行多项式拟合形成一个样条，函数不同则样条不同，最终光滑的插值曲线由多个可变样条组成，由此可以保证两个相邻的多项式及其导数在连接处连续。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate() #缺省使用线性插值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.2数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.离差标准化数据\n",
    "对原始数据做线性变化，将处理后的原始数据值映射到[0,1]的区间内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/离差标准化.png' width=150 height=150 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离差标准化的特点：经过离差标准化处理后，数据的整体分部情况不会发生改变。如果最大值和最小值相等，数据会变为0。如果数据极差（max-min）过大就会出现数据在经过离差标准化处理后，数据之间的差值非常小的情况。<br>\n",
    "离差标准化的缺点：如果样本数据中的某个值过大，那么离差标准化的结果就会接近于0，且互相之间差别很小。如遇到超过目前[min,max]的取值范围时，系统会报错，需要把min和max重新确定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.randn(5, 3), index = list('12345'), columns = ['A', 'B', 'C'])        # 随机产生5行3列的数据    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.标准差标准化的公式及特点\n",
    "标准差标准化是目前最常用的数据标准化的方法，也叫零均值标准化或分数标准化。经过该方法处理后，数据的均值为0，标准差为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/标准差标准化.png' width=110 height=110 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = (df - df.mean()) / (df.std())\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.小数定标标准化公式及对比\n",
    "小数定标标准化是通过移动小数点将数据映射到区间[-1,1]之间，移动的位数由数据绝对值的最大值决定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/小数定标.png' width=100 height=100 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df/10**np.ceil(np.log10(df.abs().max()))\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.3数据转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.处理类别数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析，多数算法模型都会对输入的数据类型进行要求，规定了数据必须为数值型。针对类别型数据，需要通过哑变量编码处理后才能输入模型中。哑变量，也叫虚拟变量( Dummy Variables），也可以称之为虚设变量或名义变量。哑变量能够将无法定量处理的变量量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='imgs/哑变量处理.png' width=400 height=200 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas库中的get_dummies函数可以对类别型数据实现哑变量编码处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'城市':['广州','上海','杭州','北京','深圳','北京','上海','杭州','广州','深圳']}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df,prefix=None,prefix_sep='_',dummy_na=False,columns=None,sparse=False,drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.将连续型数据离散化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析时，比如决策树、朴素贝叶斯等分类算法，都是基于离散型数据实现的，这时就需要将连续型数据变换成离散型数据。<br>另外，对数据的离散化处理能够减少算法运行时的时间和空间上的开销，提高系统对样本的分类聚类能力和抗噪声能力。<br>\n",
    "连续特征的离散化是指根据待离散连续数据的取值范围规定数个分段点，将连续的取值空间划分为若干个子区间，每个子区间根据数据的性质用特定的数值或者符号来表示。<br>\n",
    "因此数据的离散化涉及两个子任务，即确定分类数以及如何将连续型数据映射到这些类别型数据上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='imgs/离散化处理.png' width=300 height=400 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的离散化方法有等宽法、等频法、基于聚类分析的无监督学习方法，也包括有监督学习方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)\t等宽法\n",
    "与制作频率分布表类似，等宽法是指将数据的取值范围划分成若干具有相同宽度的区间,Pandas包内的cut函数可以进行连续型数据的等宽离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arr = pd.Series([18,23,35,54,42,21,60,63,41,38])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(arr,5, right=True, labels=None, retbins=False, precision=0, include_lowest=True) #分成5个等宽的区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)\t等频法\n",
    "等频法离散化的方法相比较于等宽法离散化而言，避免了某些区间内的类分布不均匀情况，但是依照等频离散的原理，为了保证每个区间内数据的一致性，却也有可能将原本数值非常接近的两个数值分进不同的区间，以平衡每个区间中固定的数据数，这对于最终生成模型的损坏程度不亚于等宽法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(arr,5) #分成5个等频的区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3)\t基于聚类分析的方法\n",
    "一维聚类离散的方法包括以下两个步骤：<br>第一步是用某种聚类算法（如基于划分的K-Means算法等）对连续型数据进行聚类，<br>第二步是处理聚类得到的簇，得到每个簇对应的分类值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
